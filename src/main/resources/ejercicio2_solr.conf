1. Descargar solr4 y cambiar version solr a utilizar. Pasos:
mv solr-4.10.4 to /opt/
-- crear znode en zookeeper
hbase zkcli 
> create /solr4 solr4
> close

-- crear hdfs
sudo -uhdfs hadoop fs -mkdir /user/solr

-- mv war banana 
mv /opt/solr-5.3.1/server/webapps/banana.war /opt/solr-4.10.4/example/webapps/

-- mv banana context:
mv /opt/solr-5.3.1/server/contexts/banana-context.xml /opt/solr-4.10.4/example/contexts/

-- modificar propiedad ZK_HOST
vim /opt/solr4-*/bin/solr.in.sh
> ZK_HOST="quickstart.cloudera:2181/solr4"

-- arrancar solr4:
 ./bin/solr start -c -z quickstart.cloudera:2181/solr4 -a -Dsolr.hdfs.home=hdfs://quickstart.cloudera:8020/user/solr

2. Crear carpeta de colección, copiar configuración básica por defecto (basic_schema) y modificar schema.xml: 
mkdir ejercicio2_kb
cp -R solr-5.3.1/solr/server/solr/configsets/basic_configs/ ejercicio2_config/
Modificar schema.xml para incluir campos usersha1,artname y plays:
 <fields>
   <field name="id" type="string" indexed="true" stored="true" required="true" multiValued="false" />
   <field name="usersha1" type="text_general" stored="true" indexed="true" required="true"/>
   <field name="artname" type="text_general" stored="true" indexed="true" required="true"/>
   <field name="plays" type="text_general" stored="true" indexed="true" required="true"/>
 </fields>
 
3. Crear core/collection en solr-local: 
solrctl --zk quickstart.cloudera:2181/solr4 instancedir --create ejercicio2 ejercicio2_config/
solrctl --zk quickstart.cloudera:2181/solr4 collection --create ejercicio2 -s 1 -c ejercicio2_config

4. Crear fichero morphline para completar la configuración:
Completar la propiedad SOLR_LOCATOR para añadir el nombre de la colección y el host zookeeper.
Añadir funcion readCSV() para leer los campos que se esperan indexar en la coleccion user_group_collection
Añadir un comando Morphline para convertir el campo registered_date a formato timestamp del formato yyyy-MM-dd al formato yyyy-MM-dd’T’HH:mm:ss.SSS’Z’
Añadir el comando Morphline para cargar los datos en Solr.

5. Ejecutar el programa MapReduce para almacenar los ficheros de la tabla usertopgroup: 
hadoop jar /usr/lib/solr/contrib/mr/search-mr-1.0.0-cdh5.4.2-job.jar org.apache.solr.hadoop.MapReduceIndexerTool --morphline-file user-group_morphlines.conf --output-dir hdfs://quickstart.cloudera/master/pragsis/applications/search/user-group_index --go-live --zk-host localhost:2181/solr4 --collection user-group_collection hdfs://quickstart.cloudera/user/cloudera/practica1/usertopgroup/ --mappers 1 --reducer 1
